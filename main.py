# main.py
"""
LLM Code Deployment - fully implemented main server.

Usage:
 - Put required credentials in a .env file or environment:
    GITHUB_TOKEN, GITHUB_USERNAME, SECRET, AIPIPE_TOKEN, OPENAI_BASE_URL (optional)
 - Run:
    uvicorn main:app --reload --host 0.0.0.0 --port 8000
"""

import os
import time
import base64
import json
import re
from typing import Dict, List, Tuple, Optional

import requests
from fastapi import FastAPI, Body
from fastapi.responses import JSONResponse
from dotenv import load_dotenv

load_dotenv()  # load .env if present

# ----------------------
# Configuration from env
# ----------------------
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
GITHUB_USERNAME = os.getenv("GITHUB_USERNAME")
SECRET = os.getenv("SECRET")

AIPIPE_TOKEN = os.getenv("AIPIPE_TOKEN")  # AI Pipe / OpenAI-compatible token
OPENAI_BASE_URL = os.getenv("OPENAI_BASE_URL", "https://aipipe.org/openai/v1")

if not all([GITHUB_TOKEN, GITHUB_USERNAME, SECRET]):
    raise Exception("Please set GITHUB_TOKEN, GITHUB_USERNAME, and SECRET in environment/.env")

if not AIPIPE_TOKEN:
    print("Warning: AIPIPE_TOKEN not set. LLM generation will not work until you set AIPIPE_TOKEN.")

API_BASE = "https://api.github.com"
HEADERS = {
    "Authorization": f"Bearer {GITHUB_TOKEN}",
    "Accept": "application/vnd.github+json",
    "User-Agent": "llm-code-deployment/1.0"
}

LLM_HEADERS = {
    "Authorization": f"Bearer {AIPIPE_TOKEN}",
    "Content-Type": "application/json",
}


# ------------------------
# Utilities
# ------------------------
def safe_repo_name(task: str, nonce: str) -> str:
    """Make a filesystem/GitHub-safe repo name from task + nonce."""
    repo = re.sub(r"[^a-zA-Z0-9\-_.]", "-", f"{task}-{nonce}").lower()
    return repo[:100]


def validate_secret(provided: str) -> bool:
    """Validate the provided secret against the environment secret."""
    # Note: For production use, hmac.compare_digest is usually better
    return provided == SECRET


def decode_data_uri(uri: str) -> Tuple[bytes, str]:
    """Decode a data URI and return (bytes, mime_type)."""
    match = re.match(r"data:([^;]+);base64,(.*)", uri, flags=re.S)
    if not match:
        raise ValueError("Unsupported data URI format")
    mime = match.group(1)
    b64 = match.group(2)
    content = base64.b64decode(b64)
    return content, mime


def simple_secret_scan(text: str) -> bool:
    """Heuristic scan to avoid committing obvious secrets."""
    token_patterns = [
        r"ghp_[A-Za-z0-9]{36}",  # GitHub personal access tokens
        r"sk-[A-Za-z0-9\-_]{32,}",  # OpenAI-style secret
    ]
    return any(re.search(p, text) for p in token_patterns)

def validate_llm_filepath(path: str) -> bool:
    """
    Validates a file path generated by the LLM.
    Prevents directory traversal (..), hidden files (.), and non-standard characters.
    """
    path = path.strip()
    # 1. Prevent directory traversal
    if '..' in path or path.startswith('/'):
        return False
    # 2. Prevent hidden files/directories in the root (e.g., .env, .git)
    if path.startswith('.') and ('/' not in path):
        return False
    # 3. Allow only standard file characters (alphanumeric, dots, dashes, underscores, spaces, slashes)
    if not re.match(r"^[\w\-. /]+$", path):
        return False
    return True


# ------------------------
# GitHub helpers
# ------------------------
def github_create_repo(repo_name: str, description: str = "") -> Dict:
    payload = {"name": repo_name, "private": False, "auto_init": False, "description": description}
    resp = requests.post(f"{API_BASE}/user/repos", headers=HEADERS, json=payload, timeout=30)
    if resp.status_code != 201:
        raise Exception(f"Failed to create repo ({resp.status_code}): {resp.text}")
    return resp.json()


def github_get_file_sha(owner: str, repo: str, path: str, branch: str = "main") -> Optional[str]:
    """Retrieves the SHA of a file if it exists."""
    url = f"{API_BASE}/repos/{owner}/{repo}/contents/{path}?ref={branch}"
    resp = requests.get(url, headers=HEADERS, timeout=15)
    if resp.status_code == 200:
        return resp.json().get("sha")
    return None


def github_get_latest_commit_sha(owner: str, repo: str, branch: str = "main") -> Optional[str]:
    """Retrieves the SHA of the latest commit on the specified branch."""
    url = f"{API_BASE}/repos/{owner}/{repo}/branches/{branch}"
    resp = requests.get(url, headers=HEADERS, timeout=15)
    if resp.status_code == 200:
        return resp.json().get('commit', {}).get('sha')
    return None


def github_create_or_update_file(owner: str, repo: str, path: str, content: bytes, message: str, branch: str = "main") -> Dict:
    """Create or update a file using the GitHub contents API."""
    url = f"{API_BASE}/repos/{owner}/{repo}/contents/{path}"
    content_b64 = base64.b64encode(content).decode("utf-8")
    payload = {"message": message, "content": content_b64, "branch": branch}
    existing_sha = github_get_file_sha(owner, repo, path, branch=branch)
    if existing_sha:
        payload["sha"] = existing_sha
    resp = requests.put(url, headers=HEADERS, json=payload, timeout=30)
    if resp.status_code not in (200, 201):
        raise Exception(f"Failed to create/update file '{path}' ({resp.status_code}): {resp.text}")
    return resp.json()


def github_enable_pages(owner: str, repo: str, branch: str = "main", path: str = "/") -> None:
    """Enable GitHub Pages for the repository via the Pages API."""
    url = f"{API_BASE}/repos/{owner}/{repo}/pages"
    payload = {"source": {"branch": branch, "path": path}}
    # Small delay for eventual consistency
    time.sleep(2)
    resp = requests.post(url, headers=HEADERS, json=payload, timeout=30)
    # Accept 200, 201, 202, 204 (success) or 409 (already enabled/reconfigured)
    if resp.status_code not in (200, 201, 202, 204, 409):
        raise Exception(f"Failed to enable GitHub Pages ({resp.status_code}): {resp.text}")


# ------------------------
# LLM helpers
# ------------------------
def llm_generate(prompt: str, model: str = "gpt-4o-mini", max_tokens: int = 2048, temperature: float = 0.2) -> str:
    """Call the OpenAI-compatible Chat Completions endpoint."""
    if not AIPIPE_TOKEN:
        raise Exception("AIPIPE_TOKEN not set in environment; cannot call LLM.")

    url = f"{OPENAI_BASE_URL}/chat/completions"
    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": "You are an assistant that generates minimal, professional, secure single-page static web app files. Output ONLY a valid JSON object mapping file paths to file contents. Do NOT include secrets or comments."},
            {"role": "user", "content": prompt}
        ],
        "max_tokens": max_tokens,
        "temperature": temperature,
    }
    resp = requests.post(url, headers=LLM_HEADERS, json=payload, timeout=60)
    if resp.status_code != 200:
        raise Exception(f"LLM request failed ({resp.status_code}): {resp.text}")
    try:
        return resp.json()["choices"][0]["message"]["content"]
    except Exception:
        raise Exception(f"Unexpected LLM response: {resp.text[:1000]}")


# ------------------------
# File content helpers
# ------------------------
def default_index_html() -> str:
    """Minimal default index.html placeholder."""
    return """<!doctype html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>LLM App</title>
  </head>
  <body>
    <h1>LLM App Placeholder</h1>
    <p>Code deployment successful. Awaiting LLM-generated content.</p>
  </body>
</html>
"""


def create_standard_license() -> str:
    """Generates a standard MIT license text."""
    year = time.strftime("%Y")
    return f"""MIT License

Copyright (c) {year} {GITHUB_USERNAME}

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
"""


# ------------------------
# Core logic
# ------------------------
def parse_attachments(attachments: List[Dict]) -> List[Tuple[str, bytes, str]]:
    """Parse data URI attachments."""
    parsed = []
    for att in (attachments or []):
        name = att.get("name")
        url = att.get("url")
        if not name or not url:
            continue
        if url.startswith("data:"):
            content, mime = decode_data_uri(url)
            parsed.append((name, content, mime))
        else:
            raise ValueError("Attachments must be data URIs; external URLs are not allowed")
    return parsed


def commit_initial_files(owner: str, repo: str, parsed_attachments: List[Tuple[str, bytes, str]], task: str, nonce: str, brief: str) -> Dict:
    """Create README, LICENSE, index.html and commit attachments."""
    readme_md = f"# {repo}\n\n## Project Brief\n\nTask: `{task}` (nonce {nonce})\n\n---\n\n### Round 1 Brief\n\n```\n{brief}\n```\n"
    license_txt = create_standard_license()
    index_html = default_index_html()
    commit_results = []

    # Commit core files
    for path, content, msg in [("README.md", readme_md.encode("utf-8"), "chore: add README"),
                               ("LICENSE", license_txt.encode("utf-8"), "chore: add MIT license"),
                               ("index.html", index_html.encode("utf-8"), "chore: add index.html placeholder")]:
        r = github_create_or_update_file(owner, repo, path, content, msg)
        commit_results.append(r)

    # Commit attachments
    for name, content, _ in parsed_attachments:
        name_safe = re.sub(r"[^a-zA-Z0-9._\-]", "_", name)
        path = f"attachments/{name_safe}"
        r_att = github_create_or_update_file(owner, repo, path, content, f"chore: add attachment {name_safe}")
        commit_results.append(r_att)

    # Find the latest SHA from the batch of commits (fallback)
    last_sha = None
    for r in reversed(commit_results):
        if isinstance(r, dict) and 'content' in r and 'sha' in r['content']:
            last_sha = r['content']['sha']
            break

    return {"repo_url": f"https://github.com/{owner}/{repo}", "commit_sha": last_sha}


def extract_json_block(text: str) -> str:
    """Extract the first raw JSON object from the LLM output text."""
    stripped = text.strip()
    if stripped.startswith("```"):
        lines = stripped.split('\n')
        if len(lines) > 2 and lines[-1].strip().startswith('```'):
            content = '\n'.join(lines[1:-1]).strip()
            if content.startswith('json'):
                content = content[4:].strip()
            return content
    return stripped


def post_evaluation_with_backoff(eval_url: str, payload: Dict, max_retries: int = 6) -> None:
    """Post the evaluation callback with exponential backoff."""
    delay = 1
    last_err = None
    headers = {"Content-Type": "application/json"}
    for attempt in range(max_retries):
        try:
            resp = requests.post(eval_url, headers=headers, json=payload, timeout=30)
            if resp.status_code == 200:
                print(f"Evaluation POST successful after {attempt + 1} attempts.")
                return
            else:
                last_err = f"Status {resp.status_code}: {resp.text}"
        except Exception as e:
            last_err = str(e)
        if attempt < max_retries - 1:
            print(f"Evaluation POST failed (Attempt {attempt+1}/{max_retries}). Retrying in {delay}s...")
            time.sleep(delay)
            delay = min(delay * 2, 60)
    raise Exception(f"Evaluation callback failed after {max_retries} attempts. Last error: {last_err}")


def run_round1(data: Dict) -> Dict:
    """Full round 1 flow: create repo, commit initial files, generate LLM code, deploy pages, call back."""
    required = ["email", "task", "round", "nonce", "brief", "evaluation_url"]
    for k in required:
        if k not in data:
            raise Exception(f"Missing required field: {k}")

    email, task, nonce, brief, evaluation_url = data["email"], data["task"], data["nonce"], data["brief"], data["evaluation_url"]
    attachments = data.get("attachments", [])
    repo_name = safe_repo_name(task, nonce)
    owner = GITHUB_USERNAME

    repo_json = github_create_repo(repo_name, description=f"Auto-generated repo for task {task}")
    repo_url = repo_json.get("html_url") or f"https://github.com/{owner}/{repo_name}"

    parsed_attachments = parse_attachments(attachments)
    commit_info = commit_initial_files(owner, repo_name, parsed_attachments, task, nonce, brief)
    last_sha = commit_info.get("commit_sha") or ""

    prompt = f"Brief:\n{brief}\n\nIf attachments are needed, assume attachments are present under 'attachments/' path in the repo."
    try:
        llm_out = llm_generate(prompt)
        json_text = extract_json_block(llm_out)
        try:
            files_map = json.loads(json_text)
        except json.JSONDecodeError as e:
            raise Exception(f"Failed to parse LLM JSON output: {str(e)}\nContent: {json_text[:500]}")

        # Process LLM files
        for path, content in files_map.items():
            if isinstance(content, (dict, list)):
                content = json.dumps(content)
            
            # --- START CRITICAL SANITIZATION ---
            if not validate_llm_filepath(path):
                 print(f"Refusing to commit file {path}: unsafe path detected.")
                 continue
                 
            # Prevent overwriting core files (LICENSE, README, index placeholder) and attachments
            if path.lower() in ["license", "license.txt", "readme.md"] or path.lower().startswith("attachments/"):
                print(f"Skipping LLM-generated file at restricted path: {path}")
                continue
                
            if simple_secret_scan(str(content)):
                raise Exception(f"Generated file {path} appears to include secret-like content; aborting commit.")
            # --- END CRITICAL SANITIZATION ---

            resp = github_create_or_update_file(owner, repo_name, path, str(content).encode("utf-8"), f"feat: add generated file {path}")
            if isinstance(resp, dict) and 'content' in resp and 'sha' in resp['content']:
                last_sha = resp['content']['sha']
                
        # CRITICAL FIX: Get the definitive last SHA after all LLM commits
        last_sha = github_get_latest_commit_sha(owner, repo_name) or last_sha

    except Exception as e:
        # LLM failure is not fatal; continue with initial commit SHA
        print(f"LLM generation skipped/failed: {str(e)[:200]}")
        # If LLM failed, last_sha remains the SHA from the initial commit_initial_files

    github_enable_pages(owner, repo_name)
    pages_url = f"https://{owner}.github.io/{repo_name}/"

    eval_payload = {"email": email, "task": task, "round": 1, "nonce": nonce, "repo_url": repo_url, "commit_sha": last_sha, "pages_url": pages_url}
    post_evaluation_with_backoff(evaluation_url, eval_payload)
    return {"repo_url": repo_url, "commit_sha": last_sha, "pages_url": pages_url}


def run_round2(data: Dict) -> Dict:
    """Round 2 flow: get modification brief, generate LLM code, update repo, call back."""
    required = ["email", "task", "round", "nonce", "brief", "evaluation_url"]
    for k in required:
        if k not in data:
            raise Exception(f"Missing required field: {k}")

    email, task, nonce, brief, evaluation_url = data["email"], data["task"], data["nonce"], data["brief"], data["evaluation_url"]
    repo_name = safe_repo_name(task, nonce)
    owner = GITHUB_USERNAME
    last_sha = None

    prompt = (
        "You are asked to modify the existing repo to implement the following change or feature. "
        "Output a JSON object mapping file paths to full new contents (overwrite). "
        "The file README.md MUST also be included in your output and updated to reflect the new change. "
        "Do NOT include any credentials or secrets. Keep files small and minimal.\n\n"
        f"Modification brief:\n{brief}\n\nReturn only valid JSON."
    )
    try:
        llm_out = llm_generate(prompt)
        json_text = extract_json_block(llm_out)
        try:
            files_map = json.loads(json_text)
        except json.JSONDecodeError as e:
            raise Exception(f"Failed to parse LLM JSON output: {str(e)}\nContent: {json_text[:500]}")
    except Exception as e:
        # LLM failure is fatal for round 2, as it requires changes.
        raise Exception(f"Round 2 LLM generation failed: {str(e)[:200]}")

    # Commit resulting files
    for path, content in files_map.items():
        if isinstance(content, (dict, list)):
            content = json.dumps(content)

        # --- START CRITICAL SANITIZATION ---
        if not validate_llm_filepath(path):
             raise Exception(f"Refusing to commit file {path}: unsafe path detected.")

        # Prevent overwriting protected files/folders. LICENSE must not be changed. README is mandated to change.
        if path.lower() in ["license", "license.txt"] or path.lower().startswith("attachments/"):
            print(f"Skipping LLM-generated file at restricted path: {path}")
            continue

        if simple_secret_scan(str(content)):
            raise Exception(f"Refusing to commit file {path}: secret-like content detected.")
        # --- END CRITICAL SANITIZATION ---

        resp = github_create_or_update_file(owner, repo_name, path, str(content).encode("utf-8"), f"feat: round 2 update for {path}")
        if isinstance(resp, dict) and 'content' in resp and 'sha' in resp['content']:
            last_sha = resp['content']['sha'] or last_sha

    # CRITICAL FIX: Get the definitive last SHA after all changes
    last_sha = github_get_latest_commit_sha(owner, repo_name) or last_sha

    if not last_sha:
        # If LLM generated zero files, get the current HEAD SHA to report
        last_sha = github_get_latest_commit_sha(owner, repo_name) or ""

    try:
        github_enable_pages(owner, repo_name)
    except Exception as e:
        print(f"Warning enabling pages after round2: {str(e)[:200]}")

    pages_url = f"https://{owner}.github.io/{repo_name}/"
    eval_payload = {"email": email, "task": task, "round": 2, "nonce": nonce, "repo_url": f"https://github.com/{owner}/{repo_name}", "commit_sha": last_sha, "pages_url": pages_url}
    post_evaluation_with_backoff(evaluation_url, eval_payload)

    return {"repo_url": f"https://github.com/{owner}/{repo_name}", "commit_sha": last_sha, "pages_url": pages_url}


# ------------------------
# FastAPI app
# ------------------------
app = FastAPI(title="LLM Code Deployment - Handler")


@app.post("/handle_task")
def handle_task(data: Dict = Body(...)):
    """Main endpoint that instructors will POST to."""
    try:
        if not validate_secret(data.get("secret", "")):
            return JSONResponse(status_code=401, content={"error": "Invalid secret"})

        round_num = int(data.get("round", 0))
        if round_num == 1:
            res = run_round1(data)
            return JSONResponse(status_code=200, content={"message": "Round 1 deployment initiated successfully", "result": res})
        elif round_num == 2:
            res = run_round2(data)
            return JSONResponse(status_code=200, content={"message": "Round 2 deployment initiated successfully", "result": res})
        else:
            return JSONResponse(status_code=400, content={"error": "Invalid round; expected 1 or 2"})
    except (ValueError, KeyError) as e:
        msg = str(e)
        return JSONResponse(status_code=400, content={"error": "Bad request format or missing data", "reason": msg})
    except Exception as e:
        msg = str(e)
        if len(msg) > 400:
            msg = msg[:400] + "..."
        return JSONResponse(status_code=500, content={"error": "Internal server error during deployment process", "reason": msg})


# ------------------------
# Run server
# ------------------------
if __name__ == "__main__":
    import uvicorn
    # Note: uvicorn.run here will use the simple name `main:app` which is correct 
    # when run directly or when called by the original run command: `uvicorn main:app --reload...`
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)